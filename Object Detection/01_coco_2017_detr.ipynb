{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "633ec685-c868-4204-883b-acf69b32b3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 850 is out of bounds for dimension 2 with size 850",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# 随机选择一个位置（例如中心位置）\u001b[39;00m\n\u001b[0;32m     50\u001b[0m position_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m850\u001b[39m  \u001b[38;5;66;03m# 假设特征图是25x34（196=14*14）\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m encoder_attn \u001b[38;5;241m=\u001b[39m \u001b[43mencoder_attentions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mencoder_layer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_head\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     53\u001b[0m plot_attention(\n\u001b[0;32m     54\u001b[0m     image, \n\u001b[0;32m     55\u001b[0m     encoder_attn\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m),  \u001b[38;5;66;03m# 扩展维度匹配函数输入\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     58\u001b[0m     head\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     59\u001b[0m )\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# 可视化解码器交叉注意力（图6）\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# 选择解码器最后一层（layer=5）和某个查询（query=42）\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 850 is out of bounds for dimension 2 with size 850"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "\n",
    "# 加载预训练模型和处理器\n",
    "processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\", cache_dir = \"E:/Study/facebook/\")\n",
    "model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\", output_attentions=True, cache_dir = \"E:/Study/facebook/\")\n",
    "\n",
    "# 下载示例图像\n",
    "path = \"E:/Data/coco2014/images/test2014/COCO_test2014_000000000016.jpg\"\n",
    "image = Image.open(path)\n",
    "\n",
    "# 预处理图像\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# 获取注意力权重\n",
    "encoder_attentions = outputs.encoder_attentions  # (层数, batch, head, H*W, H*W)\n",
    "decoder_attentions = outputs.decoder_attentions  # (层数, batch, head, num_queries, H*W)\n",
    "cross_attentions = outputs.cross_attentions      # (层数, batch, head, num_queries, H*W)\n",
    "\n",
    "# 可视化工具函数\n",
    "def plot_attention(image, attention_weights, title, layer=0, head=0, alpha=0.7):\n",
    "    # 将注意力权重转换为热力图\n",
    "    attn = attention_weights[layer].detach().numpy()\n",
    "    attn = attn.mean(axis=0) if attn.ndim == 3 else attn\n",
    "    \n",
    "    # 调整尺寸匹配原图\n",
    "    h, w = image.size[::-1]  # PIL图像尺寸为(width, height)\n",
    "    attn = attn.reshape(25, -1)\n",
    "    attn_resized = np.array(Image.fromarray(attn).resize((w, h), Image.BILINEAR))\n",
    "    \n",
    "    # 绘制叠加图\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(image)\n",
    "    plt.imshow(attn_resized, cmap='viridis', alpha=alpha)\n",
    "    plt.title(f\"{title} - Layer {layer} Head {head}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# ----------------------------\n",
    "# 可视化编码器自注意力（图3）\n",
    "# ----------------------------\n",
    "# 选择编码器最后一层（layer=5）的某个头（head=2）\n",
    "encoder_layer, encoder_head = 5, 2\n",
    "# 随机选择一个位置（例如中心位置）\n",
    "position_idx = 850  # 假设特征图是25x34（196=14*14）\n",
    "encoder_attn = encoder_attentions[encoder_layer][0, encoder_head, position_idx]\n",
    "\n",
    "plot_attention(\n",
    "    image, \n",
    "    encoder_attn.unsqueeze(0),  # 扩展维度匹配函数输入\n",
    "    \"Encoder Self-Attention\", \n",
    "    layer=0,  # 这里传0因为已经指定了encoder_layer\n",
    "    head=0\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 可视化解码器交叉注意力（图6）\n",
    "# ----------------------------\n",
    "# 选择解码器最后一层（layer=5）和某个查询（query=42）\n",
    "decoder_layer, query_idx = 5, 42\n",
    "# 取交叉注意力（query与编码器输出的交互）\n",
    "cross_attn = cross_attentions[decoder_layer][0, :, query_idx].mean(dim=0)  # 平均所有头\n",
    "\n",
    "plot_attention(\n",
    "    image,\n",
    "    cross_attn.unsqueeze(0),\n",
    "    \"Decoder Cross-Attention\",\n",
    "    layer=0,\n",
    "    head=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759193c8-129a-42c0-883d-6b54b9c0c3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['pixel_values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377aed19-9620-4c45-a4b3-053e8f3b1a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
