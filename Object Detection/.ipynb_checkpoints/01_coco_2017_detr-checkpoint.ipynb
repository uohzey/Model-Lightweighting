{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "633ec685-c868-4204-883b-acf69b32b3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 950 into shape (30,newaxis)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 62\u001b[0m\n\u001b[0;32m     59\u001b[0m position_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m196\u001b[39m  \u001b[38;5;66;03m# 假设特征图是14x14（196=14*14）\u001b[39;00m\n\u001b[0;32m     60\u001b[0m encoder_attn \u001b[38;5;241m=\u001b[39m encoder_attentions[encoder_layer][\u001b[38;5;241m0\u001b[39m, encoder_head, position_idx]\n\u001b[1;32m---> 62\u001b[0m \u001b[43mplot_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 直接传入一维张量\u001b[39;49;00m\n\u001b[0;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEncoder Self-Attention\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     66\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# 可视化解码器交叉注意力（图6）\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# 选择解码器最后一层（layer=5）和某个查询（query=42）\u001b[39;00m\n\u001b[0;32m     72\u001b[0m decoder_layer, query_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m42\u001b[39m\n",
      "Cell \u001b[1;32mIn[23], line 42\u001b[0m, in \u001b[0;36mplot_attention\u001b[1;34m(image, attention_weights, title, layer, head, alpha)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# 调整尺寸匹配原图\u001b[39;00m\n\u001b[0;32m     41\u001b[0m h, w \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39msize[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# PIL图像尺寸为(width, height)\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m attn \u001b[38;5;241m=\u001b[39m \u001b[43mattn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m attn_resized \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(Image\u001b[38;5;241m.\u001b[39mfromarray(attn)\u001b[38;5;241m.\u001b[39mresize((w, h), Image\u001b[38;5;241m.\u001b[39mBILINEAR))\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# 绘制叠加图\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 950 into shape (30,newaxis)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "\n",
    "# 加载预训练模型和处理器\n",
    "processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\", cache_dir = \"D:/Study/facebook/\")\n",
    "model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\", output_attentions=True, cache_dir = \"D:/Study/facebook/\")\n",
    "\n",
    "# 下载示例图像\n",
    "path = \"D:/Study/coco_2017/coco2017/test2017/000000000448.jpg\"\n",
    "image = Image.open(path)\n",
    "\n",
    "# 预处理图像\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# 获取注意力权重\n",
    "encoder_attentions = outputs.encoder_attentions  # (层数, batch, head, H*W, H*W)\n",
    "decoder_attentions = outputs.decoder_attentions  # (层数, batch, head, num_queries, H*W)\n",
    "cross_attentions = outputs.cross_attentions      # (层数, batch, head, num_queries, H*W)\n",
    "\n",
    "# 可视化工具函数\n",
    "def plot_attention(image, attention_weights, title, layer=0, head=0, alpha=0.7):\n",
    "    # 将注意力权重转换为热力图\n",
    "    attn = attention_weights[layer][0, head].detach().numpy()\n",
    "    attn = attn.mean(axis=0) if attn.ndim == 3 else attn\n",
    "    \n",
    "    # 调整尺寸匹配原图\n",
    "    h, w = image.size[::-1]  # PIL图像尺寸为(width, height)\n",
    "    attn = attn.reshape(int(np.sqrt(attn.shape[0])), -1)\n",
    "    attn_resized = np.array(Image.fromarray(attn).resize((w, h), Image.BILINEAR))\n",
    "    \n",
    "    # 绘制叠加图\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(image)\n",
    "    plt.imshow(attn_resized, cmap='viridis', alpha=alpha)\n",
    "    plt.title(f\"{title} - Layer {layer} Head {head}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# ----------------------------\n",
    "# 可视化编码器自注意力（图3）\n",
    "# ----------------------------\n",
    "# 选择编码器最后一层（layer=5）的某个头（head=2）\n",
    "encoder_layer, encoder_head = 5, 2\n",
    "# 随机选择一个位置（例如中心位置）\n",
    "position_idx = 196  # 假设特征图是14x14（196=14*14）\n",
    "encoder_attn = encoder_attentions[encoder_layer][0, encoder_head, position_idx]\n",
    "\n",
    "plot_attention(\n",
    "    image, \n",
    "    encoder_attn.unsqueeze(0),  # 扩展维度匹配函数输入\n",
    "    \"Encoder Self-Attention\", \n",
    "    layer=0,  # 这里传0因为已经指定了encoder_layer\n",
    "    head=0\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 可视化解码器交叉注意力（图6）\n",
    "# ----------------------------\n",
    "# 选择解码器最后一层（layer=5）和某个查询（query=42）\n",
    "decoder_layer, query_idx = 5, 42\n",
    "# 取交叉注意力（query与编码器输出的交互）\n",
    "cross_attn = cross_attentions[decoder_layer][0, :, query_idx].mean(dim=0)  # 平均所有头\n",
    "\n",
    "plot_attention(\n",
    "    image,\n",
    "    cross_attn.unsqueeze(0),\n",
    "    \"Decoder Cross-Attention\",\n",
    "    layer=0,\n",
    "    head=0\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
